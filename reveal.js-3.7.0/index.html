<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Fast, scalable WCOJ graph-pattern matching on in-memory graphs in Spark</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/simple.css">
    <link rel="stylesheet" href="plugin/chapter-header/chapter-header.css">
    <link rel="stylesheet" href="custom_theme.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>
<body>
<div class="reveal">
    <div class="slides">
        <section data-title="Introduction">
            <section data-no-title="true">
                <h2>Fast, scalable WCOJ graph-pattern matching on in-memory graphs in Spark</h2>
                <br>
                <h3>Presented by Per Fuchs</h3>
                <h3>Supervised by Peter Boncz and Bogdan Ghit</h3>
                <h5>Master thesis in Computer Science</h5>
            </section>
            <section>
                <h3>Cyclic queries in Graph-pattern matching pose new challenges to relational engines</h3>
                <img src="img/triangle.svg" alt="Depiction of triangle query"/>
                <img src="img/triangle-binary-joins.svg" alt="Depiction of bushy binary join tree"/>
                <aside class="notes">
                    <ul>
                        <li>Traditionally we have Snowflakes and Star joins.</li>
                        <li>Solved by binary join (two tables joined at a time).</li>
                        <li>intermediary result are in the of size linear to the inputs (PK to FK)</li>
                        <li>but graphs are FK-FK joins on the edge relationship</li>
                        <li>often cyclic</li>
                        <li>traditional binary joins are subotpimal</li>
                        <li>because they lead to huge intermediary results</li>
                        <li>which are bigger than the end result</li>
                        <li>one example: the triangle query</li>
                        <li>explain triangle, e.g. used for recommendations on Facebook</li>
                        <li>solved by the join plan depicted below</li>
                        <li>point out sizes of intermediary resutls O(N<sup>2</sup>)</li>
                        <li>compare to end result size O(N<sup>3/2</sup>)</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Why are cyclic pattern important?</h3>
                <img src="img/kite.svg" alt="Deptiction of kite query">
                <img src="img/diamond.svg" alt="Deptiction of diamond query">
                <img src="img/5-cycle.svg" alt="Deptiction of 5 cycle">
                <aside class="notes">
                    <p>the kite: an example for friends recommendation, see two triangles</p>
                    <p>diamond: used by twitter in production to recommend people to follow</p>
                    <p>circular money flows indicate bank fraud</p>
                </aside>
            </section>
            <section>
                <h3>Worst-case optimal joins to rescue</h3>
                <img src="img/triangle.svg" alt="depiction of triangle query">
                <ul>
                    <li>Idea: build the join by <i>variable-at-a-time</i></li>
                    <li>safes to build intermediary results which lead to no end result</li>
                    <li>developed 2012 and proven to be worst-case optimal, e.g. for triangles in
                    O(N<sup>3/2</sup>)</li>
                    <li>demonstrated record of high performance for circular queries TODO cites with year</li>
                </ul>
                <aside class="notes">
                    <ul>
                        <li>Explain idea</li>
                        <li>idea translated to the triangle query, bind A, bind B, find C's</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Our contributions</h3>
                <ol>
                    <li>build a scalable, parallel WCOJ in Spark</li>
                    <li>Specialize WCOJ to Graphs (not in this presentation)</li>
                </ol>
                <aside class="notes">
                    <ul>
                        <li>build a scalable WCOJ in Spark</li>
                        <ul>
                            <li>Spark is well accepted in industry and there is currently no
                                openly accessible implementation of a WCOJ in a widely used system
                            </li>
                            <li>Neo4J currently builds a Cypher frontend for Spark (stretch goal)</li>
                            <li>Well suited for long running analytical queries with its fault tolerance and
                            ability to run on many nodes</li>
                        </ul>
                        <li>Superiority over binary joins was ALWAYS - in every single paper - shown for graphs</li>
                        <ul>
                            <li>but specialization has not been considered</li>
                            <li>not in this talk but feel free to ask</li>
                            <li>We do: specialization to self joins on tables with two attributes, CSR and more</li>
                        </ul>
                    </ul>
                </aside>
            </section>
        </section>
        <section data-title="Building a scalable WCOJ in Spark">
            <section>
                <h3>Distribution of existing Spark joins</h3>
                Explain Broadcast Hash join
                <aside class="notes">
                    Note that Spark is an system which uses the Bulksynchrounous model like MapReduce (one map step (no communication),
                    one reduce step (communication by data redistribution), and so forth)
                </aside>
            </section>
            <section>
                <h3>Hypercube shuffle: n-ary joins in 1 shuffle round</h3>
                Hypecube shuffle explained using triangle query as example
                proven to be optimal in terms of communication cost in MapReduce like systems
            </section>
            <section>
                <h3>But is optimal also good?</h3>
                myria scaling, practical system
            </section>
            <section>
                <h3>Why does Hypercube shuffle not scale?</h3>
                Analysis of duplication
                main result goes towards a full broadcast,
                this is intuitively not unexpected - small world principle
            </section>
            <section>
                <h3>Caching the edge table on every node</h3>
                No communication necessary (could easily beat HC after one query because it is not query specific)
                Only one relationship needs to be shared - the edge relationship, which has only two attributes
                We optimize for memory efficiency by using CSR then most graphs fit into main memory - good idea to say this in front of
                this audience?

                parallization via logical partitioning: each worker has the full dataset but works only on parts of it (depending on the
                query)
            </section>
            <section>
                <h3>Considered logical partitionings</h3>
                HC itself, mainly to develop a better understanding of it's scaling behaviour and to see if the graph/ all data cached
                angle allows further optimizations

                simple distribution on the first attribute to bind?
                  pattern used for HP computing to parallelize search tree computations - often combined with work stealing,
                  in spark we could use adative queries (by ???intel???/???microsoft???)
            </section>
        </section>
        <section data-title="Conclusion">
            <section>
                <h3>What has been done so far?</h3>
                <ul>
                    <li>integration of a sequential Leapfrog Triejoin (WCOJ) in Spark using Scala</li>
                    <li>specialization to graphs</li>
                    <ul>
                        <li>CSR as backing data structure</li>
                        <li>specialization to two attributes tables</li>
                        <li>specialization to self-joins</li>
                        <li>logical optimization for small intersections</li>
                    </ul>
                </ul>
                <img src="results.svg" alt="diagram showing Spark joins vs WCOJ vs GraphWCOJ on SNB for a few queries">
                <aside class="notes">
                </aside>
            </section>
        </section>
        <section data-title="">
            <section data-no-title="true">
                <h2>Where to find my work?</h2>
                <h3>https://github.com/PerFuchs</h3>
                <p>Also, I'm looking for PhD opportunities or challenging positions in industry.</p>
            </section>
        </section>
        <section>
            <section data-no-title="true">
                <h2>References</h2>
            </section>
        </section>
        <section data-title="Backup slides">
            <section>
                <h3>Graph sizes in academia</h3>
            </section>
            <section>
                <h3>List of datasets</h3>
            </section>
        </section>
    </div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>
<script src="plugin/highlight/highlight.js"></script>

<script>
    Reveal.initialize({
        dependencies: [
            {src: 'plugin/markdown/marked.js'},
            {src: 'plugin/markdown/markdown.js'},
            {src: 'plugin/notes/notes.js', async: true},
            {
                src: 'plugin/chapter-header/chapter-header.js', async: true, callback: function () {
                    chapterHeader.init();
                }
            }
        ],
        controls: false,
        width: 1500,
        margin: 0.05,
        center: true,
        transition: "none"
    });
    Reveal.configure({slideNumber: true});
    Reveal.configure({slideNumber: 'c/t'});
    hljs.initHighlightingOnLoad();
</script>
</body>
</html>
