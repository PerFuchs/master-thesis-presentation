<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <title>Fast, scalable WCOJ graph-pattern matching on in-memory graphs in Spark</title>

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/simple.css">
    <link rel="stylesheet" href="plugin/chapter-header/chapter-header.css">
    <link rel="stylesheet" href="custom_theme.css">

    <!-- Theme used for syntax highlighting of code -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement('link');
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName('head')[0].appendChild(link);
    </script>
</head>
<body>
<div class="reveal">
    <div class="slides">
        <section data-title="Introduction">
            <section data-no-title="true">
                <h2>Fast, scalable WCOJ graph-pattern matching on in-memory graphs in Spark</h2>
                <br>
                <h3>Presented by Per Fuchs</h3>
                <h3>Supervised by Peter Boncz and Bogdan Ghit</h3>
                <h5>Master thesis in Computer Science</h5>
            </section>
            <section>
                <h3>Cyclic queries in Graph-pattern matching pose new challenges to relational engines</h3>
                <div class="box">
                    <div class="col-50">
                        <img height="300px" src="img/triangle.svg" alt="Depiction of triangle query"/>
                    </div>
                    <div class="col-50">
                        <img height="300px" src="img/triangle-binary-joins.svg" alt="Depiction of bushy binary join tree"/>
                    </div>
                </div>
                <p>triangles(a, b, c) <- R(a, b), S(b, c), T(c, a)</p>
                <aside class="notes">
                    <ul>
                        <li>Traditionally we have Snowflakes and Star joins.</li>
                        <li>Solved by binary join (two tables joined at a time).</li>
                        <li>intermediary result are in the of size linear to the inputs (PK to FK)</li>
                        <li>but graphs are FK-FK joins on the edge relationship</li>
                        <li>often cyclic</li>
                        <li>traditional binary joins are subotpimal</li>
                        <li>because they lead to huge intermediary results</li>
                        <li>which are bigger than the end result</li>
                        <li>one example: the triangle query</li>
                        <li>explain triangle, e.g. used for recommendations on Facebook</li>
                        <li>solved by the join plan depicted below</li>
                        <li>point out sizes of intermediary resutls O(N<sup>2</sup>)</li>
                        <li>compare to end result size O(N<sup>3/2</sup>)</li>
                        <li>this is generalizable to all queries by the so called AGM bound</li>
                        <li>Explain datalog query: one variable per vertice, one relationship per edge (all for the edge relationship -
                            alias) with attributes according to the edges
                        </li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Why are cyclic pattern important?</h3>
                <div class="box">
                    <div>
                        <h4>Facebook friends</h4>
                        <img height="300px" src="img/kite.svg" alt="Depiction of kite query">
                    </div>
                    <div>
                        <h4>Twitter followers</h4>
                        <img height="300px" src="img/diamond.svg" alt="Depiction of diamond query">
                    </div>
                    <div>
                        <h4>Bank fraud</h4>
                        <img height="300px" src="img/5-cycle.svg" alt="Depiction of 5 cycle">
                    </div>
                </div>
                <!--                TODO citations -->
                <aside class="notes">
                    <p>the kite: an example for friends recommendation, see two triangles</p>
                    <p>diamond: used by twitter in production to recommend people to follow</p>
                    <p>circular money flows indicate bank fraud</p>
                </aside>
            </section>
            <section>
                <h3>Worst-case optimal joins to rescue</h3>
                <img height="200px" src="img/triangle.svg" alt="depiction of triangle query">
                <ul>
                    <li>developed 2012 and proven to be worst-case optimal, e.g. for triangles in
                        O(N<sup>3/2</sup>)
                    </li>
                    <li>Idea: build the join by <i>variable-at-a-time</i></li>
                    <li>no intermediary results</li>
                    <li>high performance for graph-pattern matching is well established: [1] 2015, [2] 2015,
                        [3] 2017, [4] 2018
                    </li>
                    <!--                    TODO citations -->
                </ul>
                <aside class="notes">
                    <ul>
                        <li>Explain idea</li>
                        <li>idea translated to the triangle query, bind A, bind B, find C's</li>
                        <li>Note this is an n-ary join</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Our contributions</h3>
                <ol>
                    <li>integrate a scalable, parallel WCOJ in Spark</li>
                    <li>Specialize WCOJ to Graphs (not in this presentation)</li>
                </ol>
                <aside class="notes">
                    <ul>
                        <li>build a scalable WCOJ in Spark</li>
                        <ul>
                            <li>Spark is well accepted in industry and there is currently no
                                openly accessible implementation of a WCOJ in a widely used system
                            </li>
                            <li>Neo4J currently builds a Cypher frontend for Spark (stretch goal)</li>
                            <li>Well suited for long running analytical queries with its fault tolerance and
                                ability to run on many nodes
                            </li>
                        </ul>
                        <li>Superiority over binary joins was ALWAYS - in every single paper - shown for graphs</li>
                        <ul>
                            <li>but specialization has not been considered</li>
                            <li>not in this talk but feel free to ask</li>
                            <li>We do: specialization to self joins on tables with two attributes, CSR and more</li>
                        </ul>
                    </ul>
                </aside>
            </section>
        </section>
        <section data-title="Building a scalable WCOJ in Spark">
            <section>
                <h3>Distribution of existing Spark joins</h3>
                <div class="box">
                    <div class="col-60">
                        <img height="500px" src="img/spark-background.svg"/>
                    </div>
                    <div class="col-40 box">
                        <div class="col-50">
                            <table>
                                <tr>
                                    <th>a</th>
                                    <th>b</th>
                                </tr>
                                <tr>
                                    <td class="color-red">1</td>
                                    <td class="color-red">2</td>
                                </tr>
                                <tr>
                                    <td class="color-green">2</td>
                                    <td class="color-green">3</td>
                                </tr>
                                <tr>
                                    <td class="color-green">2</td>
                                    <td class="color-green">4</td>
                                </tr>
                                <tr>
                                    <td class="color-red">3</td>
                                    <td class="color-red">1</td>
                                </tr>
                            </table>
                        </div>
                        <div class="col-50">
                            <table>
                                <tr>
                                    <th>b</th>
                                    <th>c</th>
                                </tr>
                                <tr>
                                    <td class="color-blue">1</td>
                                    <td class="color-blue">2</td>
                                </tr>
                                <tr>
                                    <td class="color-blue">2</td>
                                    <td class="color-blue">3</td>
                                </tr>
                                <tr>
                                    <td>2</td>
                                    <td>4</td>
                                </tr>
                                <tr>
                                    <td class="color-blue">3</td>
                                    <td class="color-blue">1</td>
                                </tr>
                            </table>
                        </div>


                    </div>
                </div>

                <aside class="notes">
                    <ul>
                        <li>Spark organizes data in resilient distributed datasets</li>
                        <li>These are distributed onto the workers by a function chosen by a programmer, e.g. by an attribute</li>
                        <li>each worker considers only it's own tuples</li>
                        <li>communication is done via shuffles, repartitioning of the data</li>
                        <li>shuffles are expensive due to disk write and reads</li>
                        <li>computations are organized by interleaving shuffles and local computation (bulk synchrounous model</li>
                        <li>Explain join going on a (smaller) with b (large)</li>
                        <li>A join needs all data which !could! have equal keys together on one node</li>
                        <li>After organizing data one can use every ordinary join algorithm, e.g. SortMergeJoin, HashJoin</li>
                        <li>To be avoided, how to do an n-ary join in Spark?</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Distribution of existing Spark joins</h3>
                <div class="box">
                    <div class="col-60">
                        <img height="500px" src="img/spark-background.svg"/>
                    </div>
                    <div class="col-40 box">
                        <div class="col-50">
                            <table>
                                <tr>
                                    <th>a</th>
                                    <th>b</th>
                                </tr>
                                <tr>
                                    <td class="color-purple">1</td>
                                    <td class="color-purple">2</td>
                                </tr>
                                <tr>
                                    <td class="color-orange">2</td>
                                    <td class="color-orange">3</td>
                                </tr>
                                <tr>
                                    <td class="color-purple">2</td>
                                    <td class="color-purple">4</td>
                                </tr>
                                <tr>
                                    <td class="color-orange">3</td>
                                    <td class="color-orange">1</td>
                                </tr>
                            </table>
                        </div>
                        <div class="col-50">
                            <table>
                                <tr>
                                    <th>b</th>
                                    <th>c</th>
                                </tr>
                                <tr>
                                    <td class="color-blue">1</td>
                                    <td class="color-blue">2</td>
                                </tr>
                                <tr>
                                    <td class="color-blue">2</td>
                                    <td class="color-blue">3</td>
                                </tr>
                                <tr>
                                    <td>2</td>
                                    <td>4</td>
                                </tr>
                                <tr>
                                    <td class="color-blue">3</td>
                                    <td class="color-blue">1</td>
                                </tr>
                            </table>
                        </div>


                    </div>
                </div>

                <aside class="notes">
                    <ul>
                        <li>Spark organizes data in resilient distributed datasets</li>
                        <li>These are distributed onto the workers by a function chosen by a programmer, e.g. by an attribute</li>
                        <li>each worker considers only it's own tuples</li>
                        <li>communication is done via shuffles, repartitioning of the data</li>
                        <li>shuffles are expensive due to disk write and reads</li>
                        <li>computations are organized by interleaving shuffles and local computation (bulk synchrounous model</li>
                        <li>Explain join going on a (smaller) with b (large)</li>
                        <li>A join needs all data which !could! have equal keys together on one node</li>
                        <li>After organizing data one can use every ordinary join algorithm, e.g. SortMergeJoin, HashJoin</li>
                        <li>To be avoided, how to do an n-ary join in Spark?</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Hypercube shuffle: n-ary joins in 1 shuffle round</h3>
                <div class="box">
                    <div class="col-50 margin-10">
                        <h4>Idea</h4>
                        <ul>
                            <li>Organize <i>p</i> workers in an hypercube</li>
                            <li>one dimension per variable <i>i</i></li>
                            <li>configurable <i>k<sub>i</sub></i> size per dimension</li>
                            <li>such that <i>p = &#x220F;<sub>i</sub> k<sub>i</sub></i></li>
                        </ul>
                    </div>

                    <div class="col-40">
                        <p>triangles(a, b, c) <- R(a, b), S(b, c), T(c, a)</p>

                        <!--                        <img src="img/triangle.svg" alt="depiction of triangle query"/>-->
                        <img height="400px" src="img/hypercube.svg" alt="depiction of hypercube for triangle query"/>
                    </div>
                </div>
            </section>
            <section>
                <h3>Hypercube shuffle: n-ary joins in 1 shuffle round</h3>
                <div class="box">
                    <div class="col-50">
                        <img height="400px" src="img/hypercube-example.svg" alt="depiction of hypercube for triangle query"/>
                    </div>
                    <div class="col-50">
                        <p>triangles(a, b, c) <- R(a, b), S(b, c), T(c, a)</p>
                        <div class="box">
                            <div class="col-30">
                                <table>
                                    <tr>
                                        <th>a</th>
                                        <th>b</th>
                                    </tr>
                                    <tr>
                                        <td class="color-red">1</td>
                                        <td class="color-red">2</td>
                                    </tr>
                                    <tr>
                                        <td>2</td>
                                        <td>3</td>
                                    </tr>
                                    <tr>
                                        <td>2</td>
                                        <td>4</td>
                                    </tr>
                                    <tr>
                                        <td>3</td>
                                        <td>1</td>
                                    </tr>
                                </table>
                                <p class="color-red">(2, 0, *)</p>
                            </div>
                            <div class="col-30">
                                <table>
                                    <tr>
                                        <th>b</th>
                                        <th>c</th>
                                    </tr>
                                    <tr>
                                        <td>1</td>
                                        <td>2</td>
                                    </tr>
                                    <tr>
                                        <td class="color-blue">2</td>
                                        <td class="color-blue">3</td>
                                    </tr>
                                    <tr>
                                        <td>2</td>
                                        <td>4</td>
                                    </tr>
                                    <tr>
                                        <td>3</td>
                                        <td>1</td>
                                    </tr>
                                </table>
                                <p class="color-blue">(*, 0, 1)</p>
                            </div>
                            <div class="col-30">
                                <table>
                                    <tr>
                                        <th>c</th>
                                        <th>a</th>
                                    </tr>
                                    <tr>
                                        <td>1</td>
                                        <td>2</td>
                                    </tr>
                                    <tr>
                                        <td>2</td>
                                        <td>3</td>
                                    </tr>
                                    <tr>
                                        <td>2</td>
                                        <td>4</td>
                                    </tr>
                                    <tr>
                                        <td class="color-green">3</td>
                                        <td class="color-green">1</td>
                                    </tr>
                                </table>
                                <p class="color-green">(2, *, 1)</p>
                            </div>
                        </div>
                        <div class="box">
                            <div class="col-30"></div>
                        </div>
                        <div class="box">
                            <div class="col-30"></div>
                        </div>
                    </div>
                </div>
            </section>
            <!--            <section>-->
            <!--                <h3>How well does HC scale?</h3>-->
            <!--                &lt;!&ndash;                TODO remove slide? &ndash;&gt;-->
            <!--                <ul>-->
            <!--                    <li>implementation by Chu et al. 2015 in <i>Myria</i></li>-->
            <!--                    <li>speedup of of 16 for 64 workers for triangle query</li>-->
            <!--                </ul>-->
            <!--                <aside class="notes">-->
            <!--                    <ul>-->
            <!--                        <li>the question is not easy to answer</li>-->
            <!--                        <li>there is a lot of duplication going on which is query dependend and not trivial to characterize</li>-->
            <!--                        <li>only one implementation we are aware of</li>-->
            <!--                        <li>Myria scaling</li>-->
            <!--                        <li>Triangle is probably the best</li>-->
            <!--                        <li>That raises our next question:</li>-->
            <!--                    </ul>-->

            <!--                </aside>-->
            <!--            </section>-->
            <section>
                <h3>Why does Hypercube shuffle not scale?</h3>
                <img src="img/shares-bar.svg" alt="Barchart showing duplication over bigger queries."/>
                <aside class="notes">
                    <ul>
                        <li>converges to full broadcast for bigger queries</li>
                        <li>intuitively this can be explained by the small world principle</li>
                        <li>doubling the amount of workers does not help much</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Caching the edge table on all workers</h3>
                <div class="box">
                    <div class="col-50">
                        <img height="400px" src="img/hc-configuration.svg"/>
                    </div>
                    <div class="col-50">
                        <img height="400px" src="img/cached-configuartion.svg"/>
                    </div>
                </div>
                <ul>
                    <li>CSR format optimizes memory footprint</li>
                </ul>
                <aside class="notes">
                    <ul>
                        <li>If HC is optimal but converges to a full broadcast, why not cache the whole dataset on all workers
                            directly?
                        </li>
                        <li>That is query independent.</li>
                        <li>Hence, can be reused and then easily beats HC shuffle after 2 or 3 different queries</li>
                        <li>How much data needs to be cached for arbritrary graph patters?</li>
                        <li>Only one relationship of two integer attributes</li>
                        <li>Can be compressed by CSR "compressed sparse row" format</li>
                        <li>How does parallelization work then?</li>
                        <li>logical partitioning: you have all data but you consider only parts of it</li>
                    </ul>
                </aside>
            </section>
            <section>
                <h3>Parallelization via logical partitionings</h3>
                <ul>
                    <li>
                        parallelization via logical partitioning: full dataset is on each worker but it works only
                        on parts of it
                    </li>
                    <li>Hypercube</li>
                    <li>Simple distribution of the first attribute</li>
                </ul>
                <aside class="notes">
                    <ul>
                        <li>HC itself</li>
                        <li>get a better understanding of its scaling</li>
                        <li>evaluate if the new angle of having all data and being able to push it into the WCOJ enables better scaling</li>
                        <li>Another idea,</li>
                        <ul>
                            <li>WCOJ bind variables in a fixed global order, e.g. a, b, c for the triangle</li>
                            <li>partitiong the first variable</li>
                            <li>sounds simple but this is how searching a tree is parallized in high-performance computing</li>
                            <li>biggest problem skew in the data</li>
                            <li>in high-performance computing: use of workstealing -> adaptive query processing in Spark by Intel</li>
                        </ul>
                    </ul>
                </aside>
            </section>
        </section>
        <section data-title="">
            <section data-no-title="true">
                <h2>Where to find my work?</h2>
                <h3>https://github.com/PerFuchs</h3>
                <p>Also, I'm looking for PhD opportunities or challenging positions in industry.</p>
            </section>
        </section>
        <section>
            <section data-no-title="true">
                <h2>References</h2>
            </section>
        </section>
        <section data-title="Backup slides">
            <section>
                <h3>Spark vs WCOJ vs GraphWCOJ</h3>
                <img src="img/results-1.svg" alt="diagram showing Spark joins vs WCOJ vs GraphWCOJ on SNB for a few queries">
                <img src="img/results-2.svg" alt="diagram showing Spark joins vs WCOJ vs GraphWCOJ on SNB for a few queries">
                <aside class="notes">
                </aside>
            </section>
            <section>
                <h3>Graph sizes in academia</h3>
            </section>
            <section>
                <h3>List of datasets</h3>
            </section>

        </section>
    </div>
</div>

<script src="lib/js/head.min.js"></script>
<script src="js/reveal.js"></script>
<script src="plugin/highlight/highlight.js"></script>

<script>
    Reveal.initialize({
        dependencies: [
            {src: 'plugin/markdown/marked.js'},
            {src: 'plugin/markdown/markdown.js'},
            {src: 'plugin/notes/notes.js', async: true},
            {
                src: 'plugin/chapter-header/chapter-header.js', async: true, callback: function () {
                    chapterHeader.init();
                }
            }
        ],
        controls: false,
        width: 1500,
        margin: 0.05,
        center: true,
        transition: "none"
    });
    Reveal.configure({slideNumber: true});
    Reveal.configure({slideNumber: 'c/t'});
    hljs.initHighlightingOnLoad();
</script>
</body>
</html>
